{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASSIGNMENT-2\n",
    "\n",
    "Roll Numbers: 2023121013, 2023122002, 2023121006\n",
    "\n",
    "Names: Himanshu Singh, Srinath Bhamidipati, Pavan Karke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    " * Fill in the roll numbers and names of all the teams members in the cell above.\n",
    " * Code must be written in Python in Jupyter Notebooks. We highly recommend using anaconda distribution or at the minimum, virtual environments for this assignment.\n",
    " * All the code and result files should be uploaded in the github classroom.\n",
    " * You can use the in-built methods and **unless explicitly mentioned**, don't need to code from scratch for this assignment. Make sure your code is modular since you will be reusing them for future assignments.\n",
    " * All the representations are expected to be in a right-hand coordinate system. All the functions related to transformation matrices, quaternions, and 3D projection are expected to be coded by you.\n",
    " * You could split the Jupyter Notebook cells where TODO is written, but please try to avoid splitting/changing the structure of other cells.\n",
    " * All the visualization should be done inside the notebook unless specified otherwise.\n",
    " * Plagiarism will lead to heavy penalty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G2O Motion Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following motion model, you have to first generate the \"initialization\" for all the poses/vertices using the \"Given\" information. Just like in the 1D case.\n",
    "$$x_{k+1} = x_{k} + \\Delta x_{(k,k+1)} \\cos(\\theta_k) - \\Delta y_{(k,k+1)} \\sin(\\theta_k) \\\\\n",
    "y_{k+1} = y_{k} + \\Delta y_{(k,k+1)} \\cos(\\theta_k) + \\Delta x_{(k,k+1)} \\sin(\\theta_k) \\\\\n",
    "\\theta_{k+1} = \\theta_{k}+  \\Delta \\theta_{(k,k+1)}$$\n",
    "\n",
    "Even the loop closure nodes are related by the above model, except that it need not necessarily be consecutive nodes k and k+1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformation(points, transformation):\n",
    "    \"\"\" Applies a 4x4 transformation matrix to an array of points. \"\"\"\n",
    "\n",
    "    rotation = transformation[:3, :3]\n",
    "    translation = transformation[:3, 3]\n",
    "    transformed_points = (points @ rotation.T) + translation\n",
    "    return transformed_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Aligning Point Clouds using ICP (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given two 3D point clouds, P (`original_point_cloud.ply`) and Q (`transformed_point_cloud.ply`), where the second point cloud Q is a transformed version of the first point cloud P, apply the Iterative Closest Point (ICP) algorithm to align the two point clouds\n",
    "\n",
    "Implement ICP using the Levenberg-Marquardt algorithm discussed in class. Compute the registration error and visualize the quality of alignment. \n",
    "\n",
    "Compare these results with the earlier ICP with SVD. Write a brief explanation on which one performs better (both time wise and accuracy wise), and why you think that is.\n",
    "\n",
    "Correspondences are {P_i, Q_i} {i =  1 to N}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment Error: 1.7728025322685544e-07\n"
     ]
    }
   ],
   "source": [
    "def icp_svd(P, Q):\n",
    "    \"\"\" Performs Procrustes alignment on two point clouds\n",
    "    and returns the transformation matrix.\"\"\"\n",
    "\n",
    "    # Compute the mean of the point clouds\n",
    "    P_mean = np.mean(P, axis=0)\n",
    "    Q_mean = np.mean(Q, axis=0)\n",
    "\n",
    "    # Center the two point clouds around their means\n",
    "    P_centered = P - P_mean\n",
    "    Q_centered = Q - Q_mean\n",
    "\n",
    "    # Compute the cross-covariance matrix\n",
    "    W = Q_centered.T @ P_centered\n",
    "\n",
    "    # Compute the SVD of the cross-covariance matrix\n",
    "    U, S, V_t = np.linalg.svd(W)\n",
    "\n",
    "    # Compute the rotation and translation\n",
    "    R = U @ V_t\n",
    "    T = Q_mean - (R @ P_mean)\n",
    "\n",
    "    # Construct the transformation matrix\n",
    "    transformation = np.vstack((np.hstack((R, T.reshape(-1, 1))), [0, 0, 0, 1]))\n",
    "\n",
    "    return transformation\n",
    "\n",
    "# Read the point cloud\n",
    "PC_P = o3d.io.read_point_cloud(\"data/original_point_cloud.ply\")\n",
    "P = np.asarray(PC_P.points)\n",
    "\n",
    "# Read the transformed point cloud\n",
    "PC_Q = o3d.io.read_point_cloud(\"data/transformed_point_cloud.ply\")\n",
    "Q = np.asarray(PC_Q.points)\n",
    "\n",
    "# Predict the applied transformation\n",
    "T_pred = icp_svd(P, Q)\n",
    "\n",
    "# Apply the predicted transformation\n",
    "Q_pred = apply_transformation(P, T_pred)\n",
    "\n",
    "# Predicted point cloud\n",
    "PC_Q_pred = o3d.geometry.PointCloud()\n",
    "PC_Q_pred.points = o3d.utility.Vector3dVector(Q_pred)\n",
    "\n",
    "# Compute RMSE between the two transformed point clouds\n",
    "alignment_error = np.sqrt(np.mean((Q - Q_pred) ** 2))\n",
    "print('Alignment Error:', alignment_error)\n",
    "\n",
    "# Visualization\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "# vis.add_geometry(PC_P)\n",
    "vis.add_geometry(PC_Q)\n",
    "vis.add_geometry(PC_Q_pred)\n",
    "vis.poll_events()\n",
    "vis.update_renderer()\n",
    "vis.run()\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment Error: 1.7728025322685544e-07\n"
     ]
    }
   ],
   "source": [
    "def skew_symmetric(v):\n",
    "    \"\"\" Convert a vector to a skew-symmetric matrix. \"\"\"\n",
    "\n",
    "    return np.array([\n",
    "        [0, -v[2], v[1]],\n",
    "        [v[2], 0, -v[0]],\n",
    "        [-v[1], v[0], 0]\n",
    "    ])\n",
    "\n",
    "def exponential_map(xi):\n",
    "    \"\"\" Exponential map from the local tangent space to the group. \"\"\"\n",
    "\n",
    "    # Break into components\n",
    "    omega = xi[:3]\n",
    "    v = xi[3:]\n",
    "\n",
    "    # Compute rotation matrix\n",
    "    theta = np.linalg.norm(omega)\n",
    "    omega_hat = skew_symmetric(omega)\n",
    "    R = np.eye(3)\n",
    "    R += (np.sin(theta) / theta) * omega_hat\n",
    "    R += ((1 - np.cos(theta)) / (theta * theta)) * (omega_hat @ omega_hat)\n",
    "\n",
    "    # Compute transformation matrirx\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = R @ v\n",
    "    return T\n",
    "\n",
    "def icp_levenberg_marquardt(P, Q, max_iterations=50, tolerance=1e-8):\n",
    "    \"\"\" Given a transformation matrix, transforms toothless.ply\n",
    "    and recovers the transformation using Lie Group Optimization.\"\"\"\n",
    "\n",
    "    # Number of points\n",
    "    assert P.shape == Q.shape\n",
    "    num_points = P.shape[0]\n",
    "\n",
    "    # Predict the applied transformation\n",
    "    T_pred = np.eye(4)\n",
    "\n",
    "    # Iterate until max iterations\n",
    "    for iteration in range(max_iterations):\n",
    "\n",
    "        # Apply the current transformation\n",
    "        Q_pred = apply_transformation(P, T_pred)\n",
    "\n",
    "        # Compute the residuals\n",
    "        residuals = Q - Q_pred\n",
    "\n",
    "        # Compute the Jacobian matrix\n",
    "        J = np.zeros((3 * num_points, 6))\n",
    "        for idx in range(num_points):\n",
    "            J[3*idx:3*idx+3, :3] = -skew_symmetric(Q_pred[idx])\n",
    "            J[3*idx:3*idx+3, 3:] = np.eye(3)\n",
    "\n",
    "        # Compute the update using Gauss-Newton method\n",
    "        H = J.T @ J\n",
    "        g = J.T @ residuals.flatten()\n",
    "        delta_xi = np.linalg.solve(H, g)\n",
    "\n",
    "        # Update the transformation\n",
    "        delta_T = exponential_map(delta_xi)\n",
    "        T_pred = delta_T @ T_pred\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(delta_xi) < tolerance:\n",
    "            break\n",
    "\n",
    "    return T_pred\n",
    "\n",
    "# Read the point cloud\n",
    "PC_P = o3d.io.read_point_cloud(\"data/original_point_cloud.ply\")\n",
    "P = np.asarray(PC_P.points)\n",
    "\n",
    "# Read the transformed point cloud\n",
    "PC_Q = o3d.io.read_point_cloud(\"data/transformed_point_cloud.ply\")\n",
    "Q = np.asarray(PC_Q.points)\n",
    "\n",
    "# Predict the applied transformation\n",
    "T_pred = icp_svd(P, Q)\n",
    "\n",
    "# Apply the predicted transformation\n",
    "Q_pred = apply_transformation(P, T_pred)\n",
    "\n",
    "# Predicted point cloud\n",
    "PC_Q_pred = o3d.geometry.PointCloud()\n",
    "PC_Q_pred.points = o3d.utility.Vector3dVector(Q_pred)\n",
    "\n",
    "# Compute RMSE between the two transformed point clouds\n",
    "alignment_error = np.sqrt(np.mean((Q - Q_pred) ** 2))\n",
    "print('Alignment Error:', alignment_error)\n",
    "\n",
    "# Visualization\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "# vis.add_geometry(PC_P)\n",
    "vis.add_geometry(PC_Q)\n",
    "vis.add_geometry(PC_Q_pred)\n",
    "vis.poll_events()\n",
    "vis.update_renderer()\n",
    "vis.run()\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LieTorch (15 marks)\n",
    "Resources: https://github.com/princeton-vl/lietorch/tree/master\n",
    "\n",
    "The aim of this question is to use LieTorch for Pose Graph Optimization. You will be given a set of `n` noisy Transforms (representing your poses) and a set of `m` Loop Closure edges which will be generated by a function we have implemented. There are 2 parts for this question:\n",
    "1. Keep the loop closure edges constant but adjust the `n` adjacent Transforms\n",
    "2. Find a way to integrate confidence into the optimization (1 confidence value for the loop closure edges, and another for the adjacent edges), so that both the loop closure edges and the adjacent edges are optimized but to different degrees based on the confidence scores (Higher confidence implies that it's more likely that your edge is correct).\n",
    "\n",
    "**Note:** Document your loss functions along with your implementation, with suitable explanation for the design choices you make. Also print your loss values, to show them converging.\n",
    "\n",
    "Plot the original X,Y,Z values of your pose, their noisy counterparts and the new X,Y,Z values after optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTransforms():\n",
    "    '''\n",
    "    Output Format - n, m, [i, j, x, y, z, q_x, q_y, q_z, q_w] * (m+n)\n",
    "    The first n values will be the adjacent edges\n",
    "    The last m values will be the loop closure edges\n",
    "\n",
    "    '''\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How you can mimic the getTransforms function:\n",
    "Generate n random Transformations, create the loop closure edges between m of them at random, and then add noise to your original n Transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "YOUR CODE HERE\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bonus (10 marks)\n",
    "\n",
    "Implement the Pose Graph Optimization for the same G2O file as before using LieTorch, and compare the results against G2O using the Evo metrics.\n",
    "\n",
    "You are not allowed to call any external python files for this question\n",
    "\n",
    "Why is it performing better/worse?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
