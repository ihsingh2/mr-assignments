{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roll number: 2023121013, 2023122002, 2023121006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Instructions\n",
    " * Fill in the roll-number in the cell above.\n",
    " * Code must be submitted in Python in jupyter notebooks. We highly recommend using anaconda/miniconda distribution or at the minimum, virtual environments for this assignment.\n",
    " * All the code and result files should be uploaded in the github classroom.\n",
    " *  Most of the questions require you to **code your own functions** unless there is a need to call in the abilities of the mentioned libraries, such as Visualisation from Open3D. Make sure your code is modular since you will be reusing them for future assignments. All the functions related to transformation matrices, quaternions, and 3D projection are expected to be coded by you.\n",
    " *  All the representations are expected to be in a right-hand coordinate system.\n",
    "<!--  * Answer to the descriptive questions should be answered in your own words. Copy-paste answers will lead to penalty. -->\n",
    " * You could split the Jupyter Notebook cells where TODO is written, but please try to avoid splitting/changing the structure of other cells.\n",
    " * All the visualization should be done inside the notebook unless specified otherwise.\n",
    " * Plagiarism will lead to heavy penalty.\n",
    " * Commit the notebooks in the repo and any other results files under the result folder in the GitHub Classroom repo. \n",
    " * This is a group assignment. Discussions are encouraged but any sharing of code among different teams will be penalized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 1: ICP with SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Perform Procrustes alignment on two point clouds with (given) known correspondences. (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let X be your point cloud observed from the initial pose P1. You then transform it to a new pose P2. Now you wish to apply ICP to recover transformation between (X & P1) and (X & P2).\n",
    "\n",
    "Use toothless.ply point cloud and perform the alignment between the two point clouds using procrustes alignment. Your task is to write a function that takes two point clouds as input wherein the corresponding points between the two point clouds are located at the same index and returns the transformation matrix between them. Compute the alignment error after aligning the two point clouds.\n",
    "\n",
    "<b>Use root mean squared error (RSME) as the alignment error metric.</b>\n",
    "\n",
    "Make sure your code is modular as we will use this function in the next sub-part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will again use our own getTransform function to generate the 4x4 Transformation matrix to transform the pointcloud to P2, so make sure your code works for any general Transformation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTransform():\n",
    "    \"\"\" Generates a random 4x4 transformation matrix. \"\"\"\n",
    "\n",
    "    R = o3d.geometry.get_rotation_matrix_from_xyz(np.random.rand(3) * 2 * np.pi)\n",
    "    T = np.random.rand(3) * 5000\n",
    "    transformation = np.vstack((np.hstack((R, T.reshape(-1, 1))), [0, 0, 0, 1]))\n",
    "    return transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformation(points, transformation):\n",
    "    \"\"\" Applies a 4x4 transformation matrix to an array of points. \"\"\"\n",
    "\n",
    "    rotation = transformation[:3, :3]\n",
    "    translation = transformation[:3, 3]\n",
    "    transformed_points = (points @ rotation.T) + translation\n",
    "    return transformed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Transformation:\n",
      " [[ 3.27409320e-01 -1.35705634e-01 -9.35086690e-01  7.96035799e+02]\n",
      " [ 7.98500400e-01 -4.89360509e-01  3.50604339e-01  2.90643619e+03]\n",
      " [-5.05173483e-01 -8.61458225e-01 -5.18601884e-02  2.89807172e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Predicted Transformation:\n",
      " [[ 3.27409320e-01 -1.35705634e-01 -9.35086690e-01  7.96035799e+02]\n",
      " [ 7.98500400e-01 -4.89360509e-01  3.50604339e-01  2.90643619e+03]\n",
      " [-5.05173483e-01 -8.61458225e-01 -5.18601884e-02  2.89807172e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Alignment Error: 4.116292489026618e-11\n",
      "Error in Transformation: 1.782458165628076e-11\n"
     ]
    }
   ],
   "source": [
    "def icp_known_correspondences(T):\n",
    "    \"\"\" Given a transformation matrix, transforms toothless.ply\n",
    "    and recovers the transformation using Procrustes alignment.\"\"\"\n",
    "\n",
    "    # Read the point cloud\n",
    "    pcd = o3d.io.read_point_cloud(\"data/toothless.ply\")\n",
    "    X_P1 = np.asarray(pcd.points)\n",
    "\n",
    "    # Apply the transformation\n",
    "    X_P2 = apply_transformation(X_P1, T)\n",
    "\n",
    "    # Predict the applied transformation\n",
    "    T_pred = procrustes_alignment(X_P1, X_P2)\n",
    "\n",
    "    # Apply the predicted transformation\n",
    "    X_P2_pred = apply_transformation(X_P1, T_pred)\n",
    "\n",
    "    # Compute RMSE between the two transformed point clouds\n",
    "    error = np.sqrt(np.mean((X_P2 - X_P2_pred) ** 2))\n",
    "\n",
    "    return T_pred, error\n",
    "\n",
    "def procrustes_alignment(P, Q):\n",
    "    \"\"\" Performs Procrustes alignment on two point clouds\n",
    "    and returns the transformation matrix.\"\"\"\n",
    "\n",
    "    # Compute the mean of the point clouds\n",
    "    P_mean = np.mean(P, axis=0)\n",
    "    Q_mean = np.mean(Q, axis=0)\n",
    "\n",
    "    # Center the two point clouds around their means\n",
    "    P_centered = P - P_mean\n",
    "    Q_centered = Q - Q_mean\n",
    "\n",
    "    # Compute the cross-covariance matrix\n",
    "    W = Q_centered.T @ P_centered\n",
    "\n",
    "    # Compute the SVD of the cross-covariance matrix\n",
    "    U, S, V_t = np.linalg.svd(W)\n",
    "\n",
    "    # Compute the rotation and translation\n",
    "    R = U @ V_t\n",
    "    T = Q_mean - (R @ P_mean)\n",
    "\n",
    "    # Construct the transformation matrix\n",
    "    transformation = np.vstack((np.hstack((R, T.reshape(-1, 1))), [0, 0, 0, 1]))\n",
    "\n",
    "    return transformation\n",
    "\n",
    "T = getTransform()\n",
    "T_pred, alignment_error = icp_known_correspondences(T)\n",
    "T_error = np.sqrt(np.mean((T_pred - T) ** 2))\n",
    "\n",
    "print('Original Transformation:\\n', T)\n",
    "print('Predicted Transformation:\\n', T_pred)\n",
    "print('Alignment Error:', alignment_error)\n",
    "print('Error in Transformation:', T_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Implement ICP algorithm with unknown correspondences. (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to write a function that implements ICP and takes two point clouds as input wherein the correspondances are unknown. Visualize the pointclouds and plot their individual coordinate frames as you perform ICP over them. Compute the alignment error in each iteration. \n",
    "\n",
    "Refer to Shubodh's notes to compute correspondences: https://saishubodh.notion.site/Mobile-Robotics-Navigating-from-Theory-to-Application-0b65a9c20edd4081978f4ffad917febb?p=a25686ce1a11409d838d47bcac43ab4b&pm=s#bb9aaf2e316b4db3b399df1742f0444c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Transformation:\n",
      " [[-4.76142953e-01 -6.40359405e-01 -6.02683765e-01  1.90470303e+03]\n",
      " [-4.25778037e-01  7.67547723e-01 -4.79148782e-01  3.86995284e+03]\n",
      " [ 7.69415981e-01  2.84661942e-02 -6.38113410e-01  4.37413883e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Predicted Transformation:\n",
      " [[ 7.66411890e-01  2.66666391e-01 -5.84381596e-01  2.49568085e+02]\n",
      " [-6.19437760e-01  6.60107786e-02 -7.82265581e-01  8.55062094e+03]\n",
      " [ 1.70028455e-01 -9.61525669e-01 -2.15774678e-01  7.29645364e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Alignment Error: 18.555525134456627\n",
      "Error in Transformation: 1440.226846712387\n"
     ]
    }
   ],
   "source": [
    "def icp_unknown_correspondences(P, Q, num_iterations=15, visualization=True):\n",
    "    \"\"\" Given two transformation matrices, transforms and shuffles toothless.ply\n",
    "    and performs alignment on the transformed point clouds. \"\"\"\n",
    "\n",
    "    # Read the point cloud\n",
    "    pcd = o3d.io.read_point_cloud(\"data/toothless.ply\")\n",
    "    X = np.asarray(pcd.points)\n",
    "\n",
    "    # Apply the transformation\n",
    "    X_P = apply_transformation(X, P)\n",
    "    X_Q = apply_transformation(X, Q)\n",
    "\n",
    "    # Shuffle the second point cloud for unknown correspondences\n",
    "    np.random.shuffle(X_Q)\n",
    "\n",
    "    # Visualize the point clouds\n",
    "    if visualization:\n",
    "        vis = o3d.visualization.Visualizer()\n",
    "        vis.create_window()\n",
    "        PC_X_P = o3d.geometry.PointCloud()\n",
    "        PC_X_Q = o3d.geometry.PointCloud()\n",
    "        PC_X_P.points = o3d.utility.Vector3dVector(X_P)\n",
    "        PC_X_Q.points = o3d.utility.Vector3dVector(X_Q)\n",
    "        vis.add_geometry(PC_X_P)\n",
    "        vis.add_geometry(PC_X_Q)\n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()\n",
    "\n",
    "    # Initialize the error and predicted transformation\n",
    "    error = 0\n",
    "    T_pred = np.eye(4)\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        # Subsample point clouds\n",
    "        X_P_sampled = X_P[np.random.choice(X_P.shape[0], 1000, replace=False)]\n",
    "        X_Q_sampled = X_Q[np.random.choice(X_Q.shape[0], 5000, replace=False)]\n",
    "\n",
    "        # Determine corresponding pairs and align the sampled point cloud\n",
    "        distance, indices = get_nearest_neighbors(X_P_sampled, X_Q_sampled)\n",
    "        X_Q_sampled = X_Q_sampled[indices]\n",
    "\n",
    "        # Predict the applied transformation\n",
    "        T_pred_current = procrustes_alignment(X_P_sampled, X_Q_sampled)\n",
    "        T_pred = T_pred_current @ T_pred\n",
    "\n",
    "        # Apply the predicted transformation\n",
    "        X_P = apply_transformation(X_P, T_pred_current)\n",
    "        X_P_sampled = apply_transformation(X_P_sampled, T_pred_current)\n",
    "\n",
    "        # Update the visualization\n",
    "        if visualization:\n",
    "            PC_X_P.points = o3d.utility.Vector3dVector(X_P)\n",
    "            vis.update_geometry(PC_X_P)\n",
    "            vis.poll_events()\n",
    "            vis.update_renderer()\n",
    "\n",
    "        # Compute RMSE between the two subsampled point clouds\n",
    "        error = np.sqrt(np.mean((X_P_sampled - X_Q_sampled) ** 2))\n",
    "\n",
    "    # Terminate visualization\n",
    "    if visualization:\n",
    "        vis.run()\n",
    "        vis.destroy_window()\n",
    "\n",
    "    return T_pred, error\n",
    "\n",
    "def get_nearest_neighbors(P, Q):\n",
    "    dist = np.linalg.norm(P[:, np.newaxis] - Q, axis=2)\n",
    "    return np.min(dist, axis=1), np.argmin(dist, axis=1)\n",
    "\n",
    "P = getTransform()\n",
    "Q = getTransform()\n",
    "Q_pred, alignment_error = icp_unknown_correspondences(P, Q)\n",
    "Q_error = np.sqrt(np.mean((Q_pred - Q) ** 2))\n",
    "\n",
    "print('Original Transformation:\\n', Q)\n",
    "print('Predicted Transformation:\\n', Q_pred)\n",
    "print('Alignment Error:', alignment_error)\n",
    "print('Error in Transformation:', Q_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 2: ICP with Lie Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Predict the Transformation matrix between 2 point clouds with known correspondences (15 Points)\n",
    "Perform the same task as 1.1 using Lie Group Optimization from scratch to predict the transformation between the 2 point clouds.\n",
    "\n",
    "Refer: https://saishubodh.notion.site/Mobile-Robotics-Navigating-from-Theory-to-Application-0b65a9c20edd4081978f4ffad917febb?p=ee55fe5689794693910ab7861bef067b&pm=s#7b82d84766a84b63b91d859579e4886b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Transformation:\n",
      " [[ 9.00236906e-01  4.23216127e-01  1.02282071e-01  4.19823763e+03]\n",
      " [ 5.89806804e-03 -2.46747035e-01  9.69061976e-01  4.76293072e+03]\n",
      " [ 4.35360454e-01 -8.71782089e-01 -2.24626945e-01  1.99778857e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Predicted Transformation:\n",
      " [[ 9.00237172e-01  4.23215573e-01  1.02282027e-01  4.19823764e+03]\n",
      " [ 5.89775983e-03 -2.46746630e-01  9.69062081e-01  4.76293073e+03]\n",
      " [ 4.35359910e-01 -8.71782472e-01 -2.24626512e-01  1.99778858e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Alignment Error: 0.00999633841898996\n",
      "Error in Transformation: 5.0417104656567086e-06\n"
     ]
    }
   ],
   "source": [
    "def skew_symmetric(v):\n",
    "    \"\"\" Convert a vector to a skew-symmetric matrix. \"\"\"\n",
    "\n",
    "    return np.array([\n",
    "        [0, -v[2], v[1]],\n",
    "        [v[2], 0, -v[0]],\n",
    "        [-v[1], v[0], 0]\n",
    "    ])\n",
    "\n",
    "def exponential_map(xi):\n",
    "    \"\"\" Exponential map from the local tangent space to the group. \"\"\"\n",
    "\n",
    "    omega = xi[:3]\n",
    "    v = xi[3:]\n",
    "\n",
    "    theta = np.linalg.norm(omega)\n",
    "    omega_hat = skew_symmetric(omega)\n",
    "    R = np.eye(3)\n",
    "    R += (np.sin(theta) / theta) * omega_hat\n",
    "    R += ((1 - np.cos(theta)) / (theta * theta)) * (omega_hat @ omega_hat)\n",
    "\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = v\n",
    "    return T\n",
    "\n",
    "def icp_with_lie(T, max_iterations=50, tolerance=1e-6):\n",
    "    \"\"\" Given a transformation matrix, transforms toothless.ply\n",
    "    and recovers the transformation using Lie Group Optimization.\"\"\"\n",
    "\n",
    "    # Read the point cloud\n",
    "    pcd = o3d.io.read_point_cloud(\"data/toothless.ply\")\n",
    "    X_P1 = np.asarray(pcd.points)\n",
    "\n",
    "    # Apply the transformation\n",
    "    X_P2 = apply_transformation(X_P1, T)\n",
    "\n",
    "    # Add Gaussian noise to simulate practical scenarios\n",
    "    num_points = X_P2.shape[0]\n",
    "    X_P2 += 0.01 * np.random.randn(num_points, 3)\n",
    "\n",
    "    # Predict the applied transformation\n",
    "    T_pred = np.eye(4)\n",
    "    for iteration in range(max_iterations):\n",
    "        # Apply the current transformation\n",
    "        X_P2_pred = apply_transformation(X_P1, T_pred)\n",
    "\n",
    "        # Compute the residuals\n",
    "        residuals = X_P2 - X_P2_pred\n",
    "\n",
    "        # Compute the Jacobian matrix\n",
    "        J = np.zeros((3 * num_points, 6))\n",
    "        for idx in range(num_points):\n",
    "            J[3*idx:3*idx+3, :3] = -skew_symmetric(X_P2_pred[idx])\n",
    "            J[3*idx:3*idx+3, 3:] = np.eye(3)\n",
    "\n",
    "        # Compute the update using Gauss-Newton method\n",
    "        H = J.T @ J\n",
    "        g = J.T @ residuals.flatten()\n",
    "        delta_xi = np.linalg.solve(H, g)\n",
    "\n",
    "        # Update the transformation\n",
    "        delta_T = exponential_map(delta_xi)\n",
    "        T_pred = delta_T @ T_pred\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(delta_xi) < tolerance:\n",
    "            break\n",
    "\n",
    "    # Apply the predicted transformation\n",
    "    X_P2_pred = apply_transformation(X_P1, T_pred)\n",
    "\n",
    "    # Compute RMSE between the two transformed point clouds\n",
    "    error = np.sqrt(np.mean((X_P2 - X_P2_pred) ** 2))\n",
    "\n",
    "    return T_pred, error\n",
    "\n",
    "T = getTransform()\n",
    "T_pred, alignment_error = icp_with_lie(T)\n",
    "T_error = np.sqrt(np.mean((T_pred - T) ** 2))\n",
    "\n",
    "print('Original Transformation:\\n', T)\n",
    "print('Predicted Transformation:\\n', T_pred)\n",
    "print('Alignment Error:', alignment_error)\n",
    "print('Error in Transformation:', T_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 3: Pose Graph Optimization with G2O\n",
    "### Objective (5 Points)\n",
    "A robot is travelling in a oval trajectory. It is equipped with wheel odometry for odometry information and RGBD sensors for loop closure information. Due to noise in wheel odometry it generates a noisy estimate of the trajectory. Our task is to use loop closure pairs to correct the drift.\n",
    "\n",
    "We pose this problem as a pose graph optimization problem. In our graph, poses are the vertices and constraints are the edges. \n",
    "\n",
    "References:\n",
    "\n",
    "1.) Class notes: https://saishubodh.notion.site/G2O-Edge-Types-d9f9ff63c77c4ceeb84b1e49085004e3\n",
    "\n",
    "2.) Cyrill Stachniss lecture: https://www.youtube.com/watch?v=uHbRKvD8TWg "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given: \n",
    "In practical scenarios, we'd obtain the following from our sensors after some post-processing:\n",
    "\n",
    "1. Initial position\n",
    "2. Odometry Contraints/Edges: This \"edge\" information tells us relative transformation between two nodes. These two nodes are consecutive in the case of Odometry but not in the case of Loop Closure (next point).\n",
    "3. Loop Closure Contraints/Edges: Remember that while optimizing, you have another kind of \"anchor\" edge as you've seen in 1. solved example.\n",
    "\n",
    "You have been given a text file named `edges.txt` (in `data/`) which has all the above 3 and it follows G2O's format (as explained in class, [link here](https://saishubodh.notion.site/G2O-Edge-Types-d9f9ff63c77c4ceeb84b1e49085004e3) ). The ground truth is `gt.txt`.\n",
    "\n",
    "Install g2o as mentioned in `g2o.ipynb` and optimise `edges.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evo (10 Points)\n",
    "We need a measure of how good the trajectory is. The error/loss used earlier doesn't tell us much about how the trajectory differs from the ground truth. Here, we try to do just this - compute error metrics. Rather than computing these from scratch, we will just Evo - https://github.com/MichaelGrupp/evo/.\n",
    "\n",
    "Look at the absolute pose error (APE) and relative pose error (RPE). What do they capture and how are they calculated (descriptive answer)? How do these metrics differ in methodology? Can we determine if the error is more along the x/y axis?\n",
    "\n",
    "Answer the above questions and report errors for the obtained trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mapfree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
